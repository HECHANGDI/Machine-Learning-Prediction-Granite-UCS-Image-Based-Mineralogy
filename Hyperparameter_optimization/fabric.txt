#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Fracture-network generator (auto-N):
- Uses a blue-pixel budget to keep fracture ratio consistent.
- Crack COUNT is not controlled; it's estimated from the budget (or optionally fixed).
- Independently controls the sample means of length, aperture, and orientation.
- Natural morphology via oriented random walks with curvature + optional branching.

Quick examples
--------------
# 1) 20 images, 10% coverage, count auto-estimated from budget
python fracture_budget_autoN.py --out ./batch --n_images 20 --blue_coverage 0.10

# 2) Exact pixel budget; sweep LENGTH mean; hold aperture/orientation means constant
python fracture_budget_autoN.py --out ./len_sweep --n_images 10 --blue_pixels 120000 \
  --ap_mean 0.15 --ori_mean 90 --sweep length --sweep_means 4,6,8,10,12,14,16,18,20,22

# 3) Fix crack count manually (if you ever want to)
python fracture_budget_autoN.py --out ./fixedN --n_images 5 --blue_coverage 0.08 --n_fixed 120
"""

import os
import math
import json
import argparse
import zipfile
from dataclasses import dataclass, asdict
from typing import List, Tuple, Dict, Optional

import numpy as np
import pandas as pd
from PIL import Image, ImageDraw, ImageFilter


# ----------------------------- Data model -----------------------------

@dataclass
class CrackParams:
    length_mm: float
    aperture_mm: float
    orientation_deg: float


# ----------------------------- Utils -----------------------------

def truncated_normal(rng: np.random.Generator, mean: float, sd: float,
                     low: float, high: float) -> float:
    if low > high:
        low, high = high, low
    while True:
        x = rng.normal(mean, sd)
        if low <= x <= high:
            return x


def make_background(w: int, h: int, base_rgb=(234, 201, 149), noise_amp: int = 6,
                    rng: Optional[np.random.Generator] = None) -> Image.Image:
    if rng is None:
        rng = np.random.default_rng()
    base = Image.new("RGB", (w, h), base_rgb)
    arr = np.asarray(base).astype(np.int16)
    noise = rng.integers(-noise_amp, noise_amp + 1, size=(h, w, 1), dtype=np.int16)
    arr[:, :, 0] = np.clip(arr[:, :, 0] + noise[:, :, 0], 0, 255)
    arr[:, :, 1] = np.clip(arr[:, :, 1] + noise[:, :, 0] // 2, 0, 255)
    arr[:, :, 2] = np.clip(arr[:, :, 2] + noise[:, :, 0] // 3, 0, 255)
    return Image.fromarray(arr.astype(np.uint8))


def oriented_random_walk(rng: np.random.Generator, x0: float, y0: float,
                         target_len_px: float, theta_rad: float,
                         curvature_sigma: float = 0.08, step_px: float = 6.0,
                         jitter_px: float = 1.1, w: int = 768, h: int = 1536) -> List[Tuple[int, int]]:
    pts: List[Tuple[int, int]] = []
    total = 0.0
    theta = theta_rad if rng.random() < 0.5 else theta_rad + math.pi
    x, y = float(x0), float(y0)
    pts.append((int(round(x)), int(round(y))))
    max_steps = int(target_len_px / max(step_px, 1.0)) + 4
    for _ in range(max_steps):
        if total >= target_len_px:
            break
        theta += rng.normal(0.0, curvature_sigma)
        dx = step_px * math.cos(theta) + rng.normal(0.0, jitter_px)
        dy = step_px * math.sin(theta) + rng.normal(0.0, jitter_px)
        nx, ny = x + dx, y + dy
        if not (1 <= nx < w - 1 and 1 <= ny < h - 1):
            pts.append((max(1, min(w - 2, int(round(nx)))),
                        max(1, min(h - 2, int(round(ny))))))
            break
        seg_len = math.hypot(dx, dy)
        total += seg_len
        x, y = nx, ny
        pts.append((int(round(x)), int(round(y))))
    return pts


def measure_polyline_orientation_deg(pts: List[Tuple[int, int]]) -> float:
    if len(pts) < 2:
        return 0.0
    angs, wts = [], []
    for (x1, y1), (x2, y2) in zip(pts[:-1], pts[1:]):
        dx, dy = x2 - x1, y2 - y1
        L = math.hypot(dx, dy)
        if L > 0:
            angs.append(math.degrees(math.atan2(dy, dx)) % 180.0)
            wts.append(L)
    return float(np.average(angs, weights=wts)) if wts else 0.0


def adjust_sample_mean(values: np.ndarray, target_mean: float,
                       low: float, high: float, max_iter: int = 6) -> np.ndarray:
    x = values.copy()
    for _ in range(max_iter):
        if len(x) == 0:
            break
        delta = target_mean - float(x.mean())
        if abs(delta) < 1e-3:
            break
        x = np.clip(x + delta, low, high)
    return x


# ----------------------------- Pixel-budget drawing -----------------------------

def draw_with_budget(polylines: List[List[Tuple[int, int]]], widths_px: np.ndarray,
                     w: int, h: int, target_pixels: int, tolerance: float = 0.01,
                     max_iters: int = 10) -> Tuple[Image.Image, float, float]:
    """Binary-mask drawing with a *global* width scale to hit the pixel budget."""
    scale, last_err, final_scale = 1.0, 1.0, 1.0
    for _ in range(max_iters):
        mask = Image.new("L", (w, h), 0)
        d = ImageDraw.Draw(mask)
        for pts, base_w in zip(polylines, widths_px):
            ww = max(1, int(round(base_w * scale)))
            if len(pts) >= 2:
                d.line(pts, fill=255, width=ww)
        arr = np.array(mask, dtype=np.uint8)
        blue = int((arr > 0).sum())
        rel_err = abs(blue - target_pixels) / max(1, target_pixels)
        last_err, final_scale = rel_err, scale
        if rel_err <= tolerance:
            return mask, rel_err, final_scale
        factor = math.sqrt(target_pixels / max(1.0, float(blue)))  # stable
        factor = max(0.6, min(1.6, factor))
        scale *= factor
    return mask, last_err, final_scale


# ----------------------------- Auto-N estimator -----------------------------

def estimate_n_cracks(blue_pixels: int, px_per_mm: float,
                      len_mean_mm: float, ap_mean_mm: float,
                      branch_prob: float, branch_len_frac_min: float, branch_len_frac_max: float,
                      n_auto_k: float, n_jitter: float, rng: np.random.Generator) -> int:
    """
    Estimate how many cracks are needed to meet the blue-pixel budget *before*
    width scaling. Rule of thumb:
      expected_area_per_crack_px ≈ (len_mean_mm*ppm) * (ap_mean_mm*ppm) * (1 + branch_prob * mean_branch_frac)
    Then n ≈ blue_pixels / expected_area_per_crack_px, adjusted by factor n_auto_k (fudge)
    and jittered by ±n_jitter (uniform).
    """
    ppm = px_per_mm
    mean_branch_frac = 0.5 * (branch_len_frac_min + branch_len_frac_max)
    area_per_crack = (len_mean_mm * ppm) * (ap_mean_mm * ppm) * (1.0 + branch_prob * mean_branch_frac)
    area_per_crack = max(area_per_crack, 1.0)
    n_est = int(round((blue_pixels / area_per_crack) * n_auto_k))
    n_est = max(1, n_est)
    if n_jitter > 0:
        n_est = int(round(n_est * rng.uniform(1.0 - n_jitter, 1.0 + n_jitter)))
        n_est = max(1, n_est)
    return n_est


# ----------------------------- One image generation -----------------------------

def generate_one_image(index: int, p: Dict, out_dir: str,
                       w: int, h: int, px_per_mm: float,
                       blue_pixels_target: int, tolerance: float,
                       seed_base: int, line_rgb=(5, 78, 240)) -> Tuple[str, pd.DataFrame, Dict]:
    rng = np.random.default_rng(seed_base + 137 * index)

    # Decide crack count
    if p["n_fixed"] is not None:
        n_cracks = int(max(1, p["n_fixed"]))
    else:
        n_cracks = estimate_n_cracks(
            blue_pixels_target, px_per_mm,
            p["len_mean_target"], p["ap_mean_target"],
            p["branch_prob"], p["branch_len_frac_min"], p["branch_len_frac_max"],
            p["n_auto_k"], p["n_jitter"], rng
        )

    # Sample raw parameters
    L = np.array([truncated_normal(rng, p["len_mean_target"], p["len_sd"], p["len_min"], p["len_max"])
                  for _ in range(n_cracks)], dtype=float)
    A = np.array([truncated_normal(rng, p["ap_mean_target"] + p["ap_alpha"] * (l - p["len_mean_target"]),
                                   p["ap_sd"], p["ap_min"], p["ap_max"]) for l in L], dtype=float)
    O = np.array([max(0.0, min(180.0, rng.normal(p["ori_mean_target"], p["ori_sd"])))
                  for _ in range(n_cracks)], dtype=float)

    # Enforce sample-mean targets (independent control)
    L = adjust_sample_mean(L, p["len_mean_target"], p["len_min"], p["len_max"])
    A = adjust_sample_mean(A, p["ap_mean_target"], p["ap_min"], p["ap_max"])
    delta_O = p["ori_mean_target"] - (float(O.mean()) if len(O) else 0.0)
    O = np.clip(O + delta_O, 0.0, 180.0)

    # Build polylines
    polylines: List[List[Tuple[int, int]]] = []
    widths_px: List[int] = []
    for l_mm, a_mm, o_deg in zip(L, A, O):
        theta = math.radians(o_deg)
        L_px = int(round(l_mm * px_per_mm))
        x0 = rng.integers(10, w - 10)
        y0 = rng.integers(10, h - 10)
        pts = oriented_random_walk(
            rng, x0, y0, L_px, theta,
            curvature_sigma=p["curvature_sigma"],
            step_px=p["step_px"], jitter_px=p["jitter_px"], w=w, h=h
        )
        # optional branch
        if rng.random() < p["branch_prob"] and len(pts) >= 3:
            i_mid = rng.integers(1, len(pts) - 1)
            bx, by = pts[i_mid]
            frac = rng.uniform(p["branch_len_frac_min"], p["branch_len_frac_max"])
            b_len_px = max(5, int(round(frac * L_px)))
            off = rng.uniform(p["branch_angle_min_deg"], p["branch_angle_max_deg"])
            off *= (1 if rng.random() < 0.5 else -1)
            b_theta = math.radians((o_deg + off) % 180.0)
            b_pts = oriented_random_walk(
                rng, bx, by, b_len_px, b_theta,
                curvature_sigma=p["curvature_sigma"] * 1.05,
                step_px=p["step_px"], jitter_px=p["jitter_px"], w=w, h=h
            )
            if len(b_pts) >= 2:
                polylines.append(b_pts)
                widths_px.append(max(1, int(round(a_mm * px_per_mm * 0.9))))

        polylines.append(pts)
        widths_px.append(max(1, int(round(a_mm * px_per_mm))))

    widths_px = np.array(widths_px, dtype=float)

    # Draw with pixel budget
    mask, rel_err, width_scale = draw_with_budget(
        polylines, widths_px, w, h, target_pixels=blue_pixels_target,
        tolerance=tolerance, max_iters=12
    )

    # Compose final image
    bg = make_background(w, h, noise_amp=p["noise_amp"], rng=rng)
    img = bg.copy()
    arr = np.array(mask, dtype=np.uint8)
    H, W = arr.shape
    pix = img.load()
    BLUE = line_rgb
    for y in range(H):
        for x in range(W):
            if arr[y, x] > 0:
                pix[x, y] = BLUE
    img = img.filter(ImageFilter.GaussianBlur(radius=0.3))

    # Per-crack report (main polyline only)
    recs: List[CrackParams] = []
    poly_idx = 0
    for k in range(n_cracks):
        pts_main = polylines[poly_idx]
        poly_idx += 1
        recs.append(CrackParams(
            length_mm=float(L[k]),
            aperture_mm=float(A[k]),  # as designed (pre-scale)
            orientation_deg=float(measure_polyline_orientation_deg(pts_main))
        ))
    df = pd.DataFrame([asdict(r) for r in recs])

    # Save
    png_path = os.path.join(out_dir, f"fractureset_{index:02d}.png")
    img.save(png_path, "PNG")
    df.to_csv(os.path.join(out_dir, f"fractureset_{index:02d}_cracks.csv"), index=False)

    meta = {
        "image_index": index,
        "file": png_path,
        "width_px": w, "height_px": h,
        "px_per_mm": px_per_mm,
        "n_cracks": int(n_cracks),
        "blue_pixels_target": int(blue_pixels_target),
        "blue_pixels_error_rel": float(rel_err),
        "width_scale_applied": float(width_scale),
        "len_mean_mm_sample": float(df["length_mm"].mean()) if len(df) else 0.0,
        "ap_mean_mm_sample": float(df["aperture_mm"].mean()) if len(df) else 0.0,
        "ori_mean_deg_sample": float(df["orientation_deg"].mean()) if len(df) else 0.0,
        "generation_setup": p,
    }
    return png_path, df, meta


# ----------------------------- CLI -----------------------------

def parse_floats_list(s: str) -> List[float]:
    return [float(x.strip()) for x in s.split(",") if x.strip()]


def main():
    ap = argparse.ArgumentParser(
        description="Fracture image generator with blue-pixel budget and auto-estimated crack count."
    )
    ap.add_argument("--out", type=str, default="./fracture_batch")
    ap.add_argument("--n_images", type=int, default=20)
    ap.add_argument("--seed", type=int, default=20250828)
    ap.add_argument("--width", type=int, default=768)
    ap.add_argument("--height", type=int, default=1536)
    ap.add_argument("--px_per_mm", type=float, default=20.0)

    # Pixel budget: exact number or coverage fraction (default 10% if neither given)
    grp = ap.add_mutually_exclusive_group(required=False)
    grp.add_argument("--blue_pixels", type=int, default=None)
    grp.add_argument("--blue_coverage", type=float, default=None)
    ap.add_argument("--tolerance", type=float, default=0.01)
    ap.add_argument("--zip", action="store_true")

    # Length (targets control sample means)
    ap.add_argument("--len_mean", type=float, default=8.0)
    ap.add_argument("--len_sd", type=float, default=2.0)
    ap.add_argument("--len_min", type=float, default=1.2)
    ap.add_argument("--len_max", type=float, default=32.0)

    # Aperture
    ap.add_argument("--ap_mean", type=float, default=0.15)
    ap.add_argument("--ap_sd", type=float, default=0.04)
    ap.add_argument("--ap_min", type=float, default=0.02)
    ap.add_argument("--ap_max", type=float, default=0.60)
    ap.add_argument("--ap_alpha", type=float, default=0.0, help="Linear dependence on length (0 to decouple).")

    # Orientation
    ap.add_argument("--ori_mean", type=float, default=90.0)
    ap.add_argument("--ori_sd", type=float, default=18.0)

    # Morphology/style
    ap.add_argument("--curvature_sigma", type=float, default=0.08)
    ap.add_argument("--branch_prob", type=float, default=0.12)
    ap.add_argument("--branch_angle_min_deg", type=float, default=22.0)
    ap.add_argument("--branch_angle_max_deg", type=float, default=65.0)
    ap.add_argument("--branch_len_frac_min", type=float, default=0.20)
    ap.add_argument("--branch_len_frac_max", type=float, default=0.50)
    ap.add_argument("--step_px", type=float, default=6.0)
    ap.add_argument("--jitter_px", type=float, default=1.1)
    ap.add_argument("--noise_amp", type=int, default=6)

    # Crack count control (optional): fixed or auto-estimated
    ap.add_argument("--n_fixed", type=int, default=None, help="If set, use this exact number of cracks.")
    ap.add_argument("--n_auto_k", type=float, default=1.0, help="Fudge factor for auto N (1.0=neutral).")
    ap.add_argument("--n_jitter", type=float, default=0.25, help="Uniform jitter fraction for auto N (e.g., 0.25 = ±25%).")

    # Sweep which variable's *target sample mean* across images
    ap.add_argument("--sweep", choices=["length", "aperture", "orientation", None], default=None)
    ap.add_argument("--sweep_means", type=str, default=None)

    args = ap.parse_args()
    os.makedirs(args.out, exist_ok=True)

    # Resolve pixel budget
    if args.blue_pixels is None:
        cov = 0.10 if args.blue_coverage is None else float(args.blue_coverage)
        cov = min(max(cov, 0.0), 1.0)
        args.blue_pixels = int(round(cov * args.width * args.height))

    width_mm = args.width / args.px_per_mm
    height_mm = args.height / args.px_per_mm
    len_max = min(args.len_max, 0.6 * height_mm)

    # Sweep values
    sweep_vals: Optional[List[float]] = None
    if args.sweep:
        if not args.sweep_means:
            raise SystemExit("Using --sweep requires --sweep_means.")
        sweep_vals = parse_floats_list(args.sweep_means)
        if len(sweep_vals) != args.n_images:
            raise SystemExit("Length of --sweep_means must equal --n_images.")

    # Build per-image parameter dicts
    ps: List[Dict] = []
    for i in range(args.n_images):
        if args.sweep == "length":
            len_mean_target, ap_mean_target, ori_mean_target = sweep_vals[i], args.ap_mean, args.ori_mean
        elif args.sweep == "aperture":
            len_mean_target, ap_mean_target, ori_mean_target = args.len_mean, sweep_vals[i], args.ori_mean
        elif args.sweep == "orientation":
            len_mean_target, ap_mean_target, ori_mean_target = args.len_mean, args.ap_mean, sweep_vals[i]
        else:
            len_mean_target, ap_mean_target, ori_mean_target = args.len_mean, args.ap_mean, args.ori_mean

        ps.append({
            "noise_amp": args.noise_amp,

            # Targets & dists
            "len_mean_target": len_mean_target, "len_sd": args.len_sd,
            "len_min": args.len_min, "len_max": len_max,
            "ap_mean_target": ap_mean_target, "ap_sd": args.ap_sd,
            "ap_min": args.ap_min, "ap_max": args.ap_max, "ap_alpha": args.ap_alpha,
            "ori_mean_target": ori_mean_target, "ori_sd": args.ori_sd,

            # Morphology
            "curvature_sigma": args.curvature_sigma,
            "branch_prob": args.branch_prob,
            "branch_angle_min_deg": args.branch_angle_min_deg,
            "branch_angle_max_deg": args.branch_angle_max_deg,
            "branch_len_frac_min": args.branch_len_frac_min,
            "branch_len_frac_max": args.branch_len_frac_max,
            "step_px": args.step_px,
            "jitter_px": args.jitter_px,

            # Count control (auto or fixed)
            "n_fixed": args.n_fixed,
            "n_auto_k": args.n_auto_k,
            "n_jitter": args.n_jitter,
        })

    # Generate
    summaries: List[Dict] = []
    setups: List[Dict] = []
    for i, p in enumerate(ps, start=1):
        png, df, meta = generate_one_image(
            index=i, p=p, out_dir=args.out, w=args.width, h=args.height,
            px_per_mm=args.px_per_mm, blue_pixels_target=args.blue_pixels,
            tolerance=args.tolerance, seed_base=args.seed, line_rgb=(5, 78, 240)
        )
        setups.append(meta)
        summaries.append({
            "image": os.path.basename(png),
            "n_cracks": meta["n_cracks"],
            "blue_pixels_error_rel": meta["blue_pixels_error_rel"],
            "width_scale_applied": meta["width_scale_applied"],
            "len_mean_mm": meta["len_mean_mm_sample"],
            "ap_mean_mm": meta["ap_mean_mm_sample"],
            "ori_mean_deg": meta["ori_mean_deg_sample"],
        })

    pd.DataFrame(summaries).to_csv(os.path.join(args.out, "summary.csv"), index=False)
    with open(os.path.join(args.out, "generation_setups.json"), "w", encoding="utf-8") as f:
        json.dump(setups, f, indent=2)

    if args.zip:
        zip_path = os.path.join(os.path.dirname(args.out.rstrip("/")), "fracture_batch.zip")
        with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zf:
            for name in os.listdir(args.out):
                zf.write(os.path.join(args.out, name), arcname=name)
        print(f"ZIP created: {zip_path}")

    print(f"Done. Files saved in: {os.path.abspath(args.out)}")
    print(f"Summary: {os.path.join(args.out, 'summary.csv')}")


if __name__ == "__main__":
    main()
